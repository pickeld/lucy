requests
openai
flask
python-dotenv
qrcode[pil]
redis
httpx

# LlamaIndex Core
llama-index>=0.10.0
llama-index-core>=0.10.0

# LlamaIndex Integrations
llama-index-llms-openai>=0.1.0
llama-index-llms-gemini>=0.1.0
llama-index-embeddings-openai>=0.1.0
llama-index-vector-stores-qdrant>=0.2.0
llama-index-storage-chat-store-redis>=0.2.0
llama-index-storage-kvstore-redis>=0.2.0

# LlamaIndex Postprocessors & Retrievers
llama-index-postprocessor-cohere-rerank>=0.2.0

# Vector Store
qdrant-client>=1.7.0

# Data validation
pydantic>=2.0

# Utilities
retry
tiktoken>=0.5.0

# Task queue — durable background job execution
celery[redis]>=5.3.0

# Rate limiting
flask-limiter>=3.0

# Production WSGI server (multi-worker, multi-threaded)
gunicorn>=21.2.0

# Gmail OAuth2 + API
google-api-python-client>=2.0
google-auth>=2.0
google-auth-oauthlib>=1.0

# Attachment text extraction
pypdf>=3.0
python-docx>=0.8

# Calendar event generation
icalendar>=5.0.0

# Call Recordings plugin — audio transcription
# faster-whisper uses CTranslate2 backend: 4-6× faster than openai-whisper on CPU
faster-whisper>=1.0.0,<2.0
mutagen>=1.47

# Remote transcription via AssemblyAI (alternative to local Whisper)
# Includes built-in speaker diarization — no pyannote needed
assemblyai>=0.30.0

# Speaker diarization for local transcription (optional)
# Requires accepting pyannote model terms at https://huggingface.co/pyannote/speaker-diarization-3.1
# and setting HF_TOKEN in Settings → API Keys
# NOTE: torch 2.8+ hangs during CTranslate2 model loading on ARM — capped at <2.8
# NOTE: pyannote 4.x requires torchcodec which has no ARM wheel — staying on 3.3.2
# Auth is done via HF_TOKEN env var + huggingface_hub shim (use_auth_token → token)
torch>=2.0,<2.8
torchaudio>=2.0,<2.8
pyannote.audio==3.3.2
