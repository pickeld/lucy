# Shared logging config — caps container log size to prevent disk exhaustion
x-logging: &default-logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "3"

services:
  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    logging: *default-logging
    command: >
      redis-server
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
      --save 900 1
      --save 300 10
      --stop-writes-on-bgsave-error no
  # WhatsApp plugin dependency — only needed when WhatsApp plugin is enabled
  waha:
    container_name: waha
    image: devlikeapro/waha-plus:arm
    ports:
      - "3000:3000"
    volumes:
      - waha_data:/app/data
      - waha_data:/app/.sessions
      - waha_data:/app/.media
    env_file:
      - .env
    restart: unless-stopped
    logging: *default-logging
    profiles:
      - whatsapp  # Use: docker compose --profile whatsapp up

  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    logging: *default-logging
    ports:
      - "6333:6333"   # REST API + Dashboard
      - "6334:6334"   # gRPC API
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__LOG_LEVEL=INFO
      # Cap WAL size to prevent disk exhaustion
      - QDRANT__STORAGE__WAL__WAL_CAPACITY_MB=64

  app:
    build: .
    container_name: lucy
    restart: unless-stopped
    logging: *default-logging
    env_file:
      - .env
    environment:
      # Override localhost values from .env with Docker service names
      REDIS_HOST: redis
      QDRANT_HOST: qdrant
      WAHA_BASE_URL: "http://waha:3000"
      WEBHOOK_URL: "http://app:8765/webhook"
      # Celery broker — set as env var so it survives Flask hot-reloads
      CELERY_BROKER_URL: "redis://redis:6379/1"
      CELERY_RESULT_BACKEND: "redis://redis:6379/1"
    ports:
      - "8765:8765"
    volumes:
      - ./src:/app/src        # Hot reload source code
      - ./.env:/app/.env:ro   # Mount real .env (read-only, first-run seed)
      - ./data:/app/data      # SQLite settings database persistence
      - whisper_cache:/root/.cache  # Persist Whisper model downloads across restarts
      # Call Recordings: mount Dropbox folder for audio files (read-write for uploads)
      - /Users/dpickel/Library/CloudStorage/Dropbox/call_recordings:/app/data/call_recordings
    depends_on:
      redis:
        condition: service_started
      qdrant:
        condition: service_started
    healthcheck:
      # Use /health/live (liveness) not /health (readiness) so transient
      # dependency failures don't mark the container unhealthy
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8765/health/live', timeout=5).raise_for_status()"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # -------------------------------------------------------------------------
  # Celery workers — durable background task execution
  # -------------------------------------------------------------------------
  # Default queue: WhatsApp message processing, entity extraction
  worker:
    build: .
    container_name: lucy-worker
    restart: unless-stopped
    logging: *default-logging
    env_file:
      - .env
    environment:
      REDIS_HOST: redis
      QDRANT_HOST: qdrant
      WAHA_BASE_URL: "http://waha:3000"
      CELERY_REDIS_DB: "1"
    command: >
      celery -A tasks worker
      --loglevel=info
      -Q default
      --concurrency=4
      -n worker-default@%h
    volumes:
      - ./src:/app/src
      - ./.env:/app/.env:ro
      - ./data:/app/data
    depends_on:
      redis:
        condition: service_started
      qdrant:
        condition: service_started

  # Heavy queue: Whisper transcription (concurrency=1 to avoid OOM)
  worker-heavy:
    build: .
    container_name: lucy-worker-heavy
    restart: unless-stopped
    logging: *default-logging
    env_file:
      - .env
    environment:
      REDIS_HOST: redis
      QDRANT_HOST: qdrant
      WAHA_BASE_URL: "http://waha:3000"
      CELERY_REDIS_DB: "1"
    command: >
      celery -A tasks worker
      --loglevel=info
      -Q heavy
      --concurrency=1
      -n worker-heavy@%h
    volumes:
      - ./src:/app/src
      - ./.env:/app/.env:ro
      - ./data:/app/data
      - whisper_cache:/root/.cache
      - /Users/dpickel/Library/CloudStorage/Dropbox/call_recordings:/app/data/call_recordings
    depends_on:
      redis:
        condition: service_started
      qdrant:
        condition: service_started

  # Celery Beat — periodic task scheduler for Scheduled Insights
  worker-beat:
    build: .
    container_name: lucy-worker-beat
    restart: unless-stopped
    logging: *default-logging
    env_file:
      - .env
    environment:
      REDIS_HOST: redis
      QDRANT_HOST: qdrant
      WAHA_BASE_URL: "http://waha:3000"
      CELERY_BROKER_URL: "redis://redis:6379/1"
      CELERY_RESULT_BACKEND: "redis://redis:6379/1"
    command: >
      celery -A tasks beat
      --loglevel=info
      --schedule=/tmp/celerybeat-schedule
    volumes:
      - ./src:/app/src
      - ./.env:/app/.env:ro
      - ./data:/app/data
    depends_on:
      redis:
        condition: service_started

  ui:
    build: ./ui-reflex
    container_name: lucy-ui
    restart: unless-stopped
    logging: *default-logging
    environment:
      API_URL: "http://app:8765"           # Server-to-server (Reflex backend → Flask)
      PUBLIC_API_URL: "http://localhost:8765"  # Browser-facing (iframe src)
    ports:
      - "3001:3000"   # Reflex frontend (3000 taken by WAHA)
      - "8000:8000"   # Reflex backend (must match frontend's expected port)
    volumes:
      - ./ui-reflex/ui_reflex:/app/ui_reflex          # Hot reload Python source
      - ./ui-reflex/assets:/app/assets                  # Hot reload static assets
      - ./ui-reflex/rxconfig.py:/app/rxconfig.py        # Config changes
    depends_on:
      app:
        condition: service_healthy

volumes:
  waha_data:
  redis_data:
  qdrant_data:
  whisper_cache: